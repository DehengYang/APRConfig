| **Bias Name**                                           | **Time when the bias was revealed**                   | **Study Revealing the bias**                                                                                                                                                              | **Paper Link**                                                                                                                                                                                                                                                                                                                      | **Bias Definition**                                                                                                                                                  | **Explanation about why this is a bias**                                                                                                                                                                                                                                                                                                                                                                                                                                       | **Bias Mitigation Judgement Criteria/Bias Mitigation Guidelines**                                                                                                                                                                                                                                                                                                                 |
|---------------------------------------------------------|-------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Defect classes selection bias                           | 2014                                                  | A critical review of "automatic patch generation learned from human-written patches": Essay on the problem statement and the evaluation of automatic software repair                  | https://dl.acm.org/doi/abs/10.1145/2568225.2568324                                                                                                                                                                                                                                                                                  | Using inconsistent defect classes when evaluating multiple APR techniques.                                                                                           | Using inconsistent defect classes for evaluation could cause serious consequences on the conclusiveness of effectiveness evaluation of an APR technique, as stated by Monperrus.                                                                                                                                                                                                                                                                                               | Rigorously, automatic repair approaches can be compared only if they address similar defect classes. It would also be considered that the bias is mitigated, to a certain extent, when multiple APR techniques are evaluated on the same datasets.                                                                                                                     |
| Fix acceptability metric bias                           | 2014                                                  | A critical review of "automatic patch generation learned from human-written patches": Essay on the problem statement and the evaluation of automatic software repair                  | https://dl.acm.org/doi/abs/10.1145/2568225.2568324                                                                                                                                                                                                                                                                                  | Using fix acceptability (i.e., asking developers to assess whether the APR-generated patch is more acceptable) as an evaluation metric.                              | Asking developers to assess the fix acceptability does not rate the inner quality of the patch, but more on whether the code “looks good’ or not, as stated by Monperrus.                                                                                                                                                                                                                                                                                                      | The bias is mitigated if the fix acceptability metric (i.e., manually judging if the APR-generated patch is acceptable) is not used in the APR evaluation.                                                                                                                                                                                                             |
| Non-manual validation bias                              | 2015                                                  | An analysis of patch plausibility and correctness for generate-and-validate patch generation systems                                                                                      | https://dl.acm.org/doi/abs/10.1145/2771783.2771791                                                                                                                                                                                                                                                                                  | Assessing the correctness of APR-generated patches without manual validation.                                                                                        | The patches generated by APR techniques that pass all test cases may be incorrect. This patch correctness asssessment could be biased without manual validation.                                                                                                                                                                                                                                                                                                               | The bias is mitigated if the APR-generated patch is validated manually.                                                                                                                                                                                                                                                                                                |
| Non-independent test validation bias                    | 2015                                                  | Is the cure worse than the disease? overfitting in automated program repair                                                                                                               | https://dl.acm.org/doi/abs/10.1145/2786805.2786825                                                                                                                                                                                                                                                                                  | Assessing the correctness of APR-generated patches without held-out tests that are not included in the original test suite used in patch validation.                 | The patches generated by APR techniques that pass all test cases may be incorrect. This patch correctness asssessment could be biased without validation of held-out tests.                                                                                                                                                                                                                                                                                                    | The bias is mitigated if the APR-generated patch is assessed by held-out tests that are not included in the original test suite used in patch validation.                                                                                                                                                                                                              |
| NCP vs. NTCE metric bias                                | 2018                                                  | How to Measure the Performance of Automated Program Repair                                                                                                                                | https://ieeexplore.ieee.org/abstract/document/8612557/                                                                                                                                                                                                                                                                              | Using Number of Test Case Executions (NTCE for short) as an efficiency metric rather than Number of Candidate Patches before a valid patch is found (NCP for short). | As stated by Qi et al., as the overhead of running different test cases can be distinct, the overhead (in terms of NTCE) of validating one candidate patch in different programs is also distinct because programs often ship with different size of test cases used for regression test, which results in the bias to programs coming with small size of test cases. Thus, they propose the metric of NCP to avoid bias possibly introduced by the metric of test executions. | The bias does not exist at all if the repair efficiency is not evaluated in the paper. The bias is mitigated if the NCP metric is used during the APR evaluation.                                                                                                                                                                                                      |
| Defect classes evaluation bias                          | 2018                                                  | Do automated program repair techniques repair hard and important bugs?                                                                                                                    | https://link.springer.com/article/10.1007/s10664-017-9550-0                                                                                                                                                                                                                                                                         | Whether APR techniques can repair hard and important bugs are not evaluated.                                                                                         | The evaluation of an APR technique could be biased without evaluating whether it can repair hard and imporant bugs.                                                                                                                                                                                                                                                                                                                                                            | Rigorously, it is expected that the researchers could discuss the complexity and importance of repaired bugs using the metrics proposed by the bias study (e.g., Priority of the Defect). It would also be considered that the bias is mitigated, to a certain extent, when the repaired defect are publicly available for further check or are dicussed in the paper. |
| Only-manual validation bias                             | 2019                                                  | On reliability of patch correctness assessment                                                                                                                                            | https://ieeexplore.ieee.org/abstract/document/8812054/                                                                                                                                                                                                                                                                              | Assessing the correctness of APR-generated patches by only using author annotation.                                                                                  | Only using author annotation for patch correctness assessment could be biasd, and using independent test suite can be used to augment author annotation.                                                                                                                                                                                                                                                                                                                       | The bias does not exist at all if no manual check are perfermed for APR-generated patch correctness assessment. Or the bias is mitigated if both held-out tests and manual check are used for patch correctness assessment.                                                                                                                                            |
| Only-independent test validation bias                                        | 2019                                                  | On reliability of patch correctness assessment                                                                                                                                            | https://ieeexplore.ieee.org/abstract/document/8812054/                                                                                                                                                                                                                                                                              | Assessing the correctness of APR-generated patches by only using held-out tests that are not included in the original test suite used in patch validation.           | As stated by Le et al., independent test suite (ITS) alone should not be used to evaluate the effectiveness of APR techniques.                                                                                                                                                                                                                                                                                                                                                 | The bias does not exist at all if no held-out tests are used for APR-generated patch correctness assessment. Or the bias is mitigated if both held-out tests and manual check are used for patch correctness assessment.                                                                                                                                               |
| Fault localization bias                                 | 2019                                                  | You cannot fix what you cannot find! an investigation of fault localization bias in benchmarking automated program repair systems                                                         | https://ieeexplore.ieee.org/abstract/document/8730164/                                                                                                                                                                                                                                                                              | Using inconsistent fault localization configurations when evaluating APR techniques.                                                                                 | Using inconsistent fault localization configurations could lead to significant different results in terms of repair effectiveness.                                                                                                                                                                                                                                                                                                                                             | The bias does not exist at all when no fault localization is performed. The bias is mitigated if multiple APR techniques use the same fault localization confirguration during evaluation.                                                                                                                                                                             |
| Subject bugs selection bias                             | 2019                                                  | Attention please: Consider Mockito when evaluating newly proposed automated program repair techniques                                                                                     | https://dl.acm.org/doi/abs/10.1145/3319008.3319349                                                                                                                                                                                                                                                                                  | Excluding Mockito bugs when evaluating APR techniques with Defects4J.                                                                                                | Not considering bugs in Mockito project of Defects4J dataset could lead to biased repair results.                                                                                                                                                                                                                                                                                                                                                                              | The bias does not exist at all when Defects4j is not used. The bias is mitigated if the Mockito bugs are included when using Defects4J for evaluation.                                                                                                                                                                                                                 |
| Flaky test inclusion bias                               | 2019                                                  | "Flakime: Laboratory-controlled test flakiness impact assessment. a case study on mutation testing and program repair" & "On the Impact of Flaky Tests in Automated Program Repair" | https://arxiv.org/abs/1912.03197 & https://ieeexplore.ieee.org/abstract/document/9425948/ | Including flaky tests when evaluating APR techniques. | The inclusion of flaky tests has a significant impact on repair performance.                                                                                                              | Rigorously, the bias is very hard to mitigate as it is hard to identify if there exist flaky tests in the bug dataset. However, eliminating flaky tests is still an open challenge. Thus, it would also be considered that the bias is mitigated, to a certain extent, when only a few tests are used or curated datasets are used. |
| Benchmark selection bias                                | 2019                                                  | Empirical review of Java program repair tools: a large-scale experiment on 2,141 bugs and 23,551 repair attempts                                                                          | https://dl.acm.org/doi/abs/10.1145/3338906.3338911                                                                                                                                                                                                                                                                                  | Using a single dataset when evaluating APR techniques.                                                                                                               | Using only a single dataset could lead to biased repair results.                                                                                                                                                                                                                                                                                                                                                                                                               | Rigorously, the bias is mitigated if multiple datasets are used for APR evaluation. It would also be considered that the bias is mitigated, to a certain extent, when buggy programs from different sources are used.                                                                                                                                                  |
| NCP vs. Time metric bias                                | 2020                                                  | On the Efficiency of Test Suite based Program Repair: A Systematic Assessment of 16 Automated Repair Systems for Java Programs                                                            | https://dl.acm.org/doi/abs/10.1145/3377811.3380338                                                                                                                                                                                                                                                                                  | Using repair time as an efficiency metric rather than the NCP.                                                                                                       | As stated by Liu et al., Time budgets could introduce biases for different bugs, and NCP could avoid such biases.                                                                                                                                                                                                                                                                                                                                                              | The bias does not exist at all if the repair efficiency is not evaluated in the paper. The bias is mitigated if the NCP metric is discussed during the APR evaluation.                                                                                                                                                                                                 |
| Tool exception bias                                     | 2020                                                  | Understanding the Non-Repairability Factors of Automated Program Repair Techniques                                                                                                        | https://ieeexplore.ieee.org/abstract/document/9359317                                                                                                                                                                                                                                                                               | Not addressing  exceptions of APR techniques during the evaluation when calculating the recall metric.                                                               | The measure of recall could be biased if considering bug repair trials with runtime exceptions.                                                                                                                                                                                                                                                                                                                                                                                | The bias does not exist at all if repair recall metric is not calculated. The bias is mitigated if bug fixing attempts that ended with unexpected results are excluded when calculating unexpected results.                                                                                                                                                            |
| Bug processing bias                                     | 2021                                                  | A critical review on the evaluation of automated program repair systems                                                                                                                   | https://www.sciencedirect.com/science/article/pii/S0164121220302156                                                                                                                                                                                                                                                                 | Using future test cases that are not available at the time of the bug is reported for dataset construction.                                                          | As stated by Liu et al., although APR benchmarks are often built from real-world project data, many bugs are actually processed leading to a bias in validating that APR tools are ready for production environments. Future test cases should be removed when evaluating APR techniques.                                                                                                                                                                                      | The bias is mitigated when buggy programs with future test cases are excluded during the APR evaluation.                                                                                                                                                                                                                                                               |
| NTCE vs. NCP metric bias                                | 2021                                                  | How Does Regression Test Selection Affect Program Repair? An Extensive Study on 2 Million Patches                                                                                         | https://arxiv.org/abs/2105.07311                                                                                                                                                                                                                                                                                                    | Using NCP as an efficiency metric rather than NTCE.                                                                                                                  | As stated by Lou et al., the number of patches  (i.e., NCP) widely used for measuring APR efficiency can incur skewed conclusions. Using NTCE can avoid such bias.                                                                                                                                                                                                                                                                                                             | The bias does not exist at all if the repair efficiency is not evaluated in the paper. The bias is mitigated if the NTCE metric (i.e., Number of Test Case Executions) is used during the APR evaluation.                                                                                                                                                              |
| Inaccurate ground truth bias                            | 2021                                                  | Is the Ground Truth Really Accurate? Dataset Purification for Automated Program Repair                                                                                                    | https://ieeexplore.ieee.org/abstract/document/9426017/                                                                                                                                                                                                                                                                              | Using inaccurate ground truth (i.e., human-written patches) to assess correctness of APR-generated patches.                                                          | Inaccurate ground truth (i.e., human written patches that are tangled with features or refactorings) may introduce bias and pose threats to the reliability of manual patch correctness assessment.                                                                                                                                                                                                                                                                            | "Rigorously, the bias is mitigated if no inaccurate ground truth are used for patch correctness assessment. Similar to the ""Flaky test inclusion bias"",  it might be very hard for us to identify if the ground truth patch is really accurate."                                                                                                                     |
